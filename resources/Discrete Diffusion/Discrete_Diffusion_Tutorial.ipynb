{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discrete Diffusion (D3PM) \u2013 Practical\n",
        "\n",
        "Interactive, hands-on introduction to discrete diffusion models (D3PMs). Built as a sequel to the continuous diffusion session; assumes comfort with probability and the Gaussian version.\n",
        "\n",
        "**You will:**\n",
        "- Build the discrete forward process via categorical transition matrices.\n",
        "- Derive and code the exact posterior $q(x_{t-1} \\mid x_t, x_0)$ and sample with Gumbel-max.\n",
        "- Implement the hybrid D3PM loss (VB term + CE on $x_0$ logits).\n",
        "- Train a tiny D3PM on MNIST (quantized) and sample class-conditional images.\n",
        "- Probe the process interactively (sliders for $t$, corruption visualization).\n",
        "\n",
        "**Run order:** top-to-bottom. Coding exercises are clearly marked; downstream cells expect them to be filled. If time is short, focus on Sections 1\u20135 and use the provided small training loop.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Why discrete diffusion?\n",
        "- Data are categorical/quantized (tokens, color bins); Gaussian noise is a poor fit.\n",
        "- Forward process: multiply by categorical transition matrices instead of adding Gaussian noise.\n",
        "- Reverse process: model predicts $x_0$ logits; exact posterior $q(x_{t-1}\\mid x_t, x_0)$ is closed-form.\n",
        "- Sampling uses Gumbel-max instead of reparameterized Gaussians.\n",
        "\n",
        "We will derive each component, implement it, and immediately probe it with toy checks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "- Keep runtime light: we use small channel sizes and few diffusion steps for class time.\n",
        "- If GPU is available, use it; CPU will work but slower for training/sampling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math\n",
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', DEVICE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1 \u2013 Discrete forward process\n",
        "\n",
        "We corrupt categorical data with a transition matrix $Q^{(t)}$ each step. For simplicity we start with **uniform corruption** governed by a noise schedule $\beta_t$.\n",
        "\n",
        "- One-step matrix (uniform): $Q^{(t)} = (1 - \beta_t) I + \beta_t \\cdot \tfrac{1}{K}\\mathbf{1}\\mathbf{1}^T$.\n",
        "- Cumulative: $Q_{1:t} = Q^{(1)} Q^{(2)} \\dots Q^{(t)}$.\n",
        "\n",
        "We will: (1) build these matrices, (2) visualize how the distribution flattens as $t$ grows.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Theory:** For K categories and noise schedule $\beta_t$, one-step corruption is\n",
        "$$Q^{(t)} = (1-\beta_t) I + \beta_t \tfrac{1}{K}\\mathbf{1}\\mathbf{1}^T,$$\n",
        "so each step keeps the original label w.p. $1-\beta_t$ and otherwise jumps uniformly. The cumulative\n",
        "$$Q_{1:t} = Q^{(1)} Q^{(2)} \\cdots Q^{(t)}$$\n",
        "flattens the distribution as $t\to T$ (entropy increases). We will build these matrices and verify row-stochasticity/entropy growth.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Exercise 1: One-step and cumulative transition matrices\n",
        "Implement `make_uniform_q_onestep` and `cumulative_q` so rows sum to 1 and cumulative entropy grows with t.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Check: shapes and entropy monotonicity\n",
        "K, T = 3, 5\n",
        "betas = torch.linspace(0.01, 0.2, T)\n",
        "q1 = make_uniform_q_onestep(K, betas)\n",
        "assert q1.shape == (T, K, K)\n",
        "    assert torch.allclose(q1.sum(-1), torch.ones_like(q1.sum(-1)))\n",
        "qcum = cumulative_q(q1)\n",
        "x0 = torch.tensor([0])\n",
        "probs_t = [qcum[t, x0] for t in range(T)]\n",
        "ents = [-(p * p.log()).sum().item() for p in probs_t]\n",
        "print(\"Entropies by t:\", ents)\n",
        "assert all(ents[i] <= ents[i+1] + 1e-6 for i in range(len(ents)-1))\n",
        "print(\"Exercise 1 check passed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "def make_uniform_q_onestep(num_classes: int, betas: torch.Tensor) -> torch.Tensor:\n",
        "    # Build T one-step transition matrices for uniform corruption.\n",
        "    mats = []\n",
        "    for beta in betas:\n",
        "        # with prob (1 - beta) stay; otherwise jump uniformly\n",
        "        mat = torch.ones(num_classes, num_classes, dtype=torch.float64) * (beta / num_classes)\n",
        "        mat.fill_diagonal_(1 - (num_classes - 1) * beta / num_classes)\n",
        "        mats.append(mat)\n",
        "    return torch.stack(mats, dim=0)\n",
        "\n",
        "\n",
        "def cumulative_q(q_onestep: torch.Tensor) -> torch.Tensor:\n",
        "    # Multiply one-step matrices to get cumulative Q_{1:t} for all t.\n",
        "    qs = []\n",
        "    acc = q_onestep[0]\n",
        "    qs.append(acc)\n",
        "    for i in range(1, q_onestep.shape[0]):\n",
        "        acc = acc @ q_onestep[i]\n",
        "        qs.append(acc)\n",
        "    return torch.stack(qs, dim=0)\n",
        "\n",
        "# toy example (kept for exploration)\n",
        "K = 4\n",
        "T = 10\n",
        "betas = torch.linspace(1e-3, 0.15, T)\n",
        "q1 = make_uniform_q_onestep(K, betas)\n",
        "qcum = cumulative_q(q1)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
        "for ax, t in zip(axes, [0, 4, 9]):\n",
        "    sns.heatmap(qcum[t].numpy(), ax=ax, vmin=0, vmax=1, cmap='magma', cbar=False)\n",
        "    ax.set_title(f'Q_1:{t+1}')\n",
        "plt.tight_layout(); plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2 \u2013 Posterior $q(x_{t-1} \\mid x_t, x_0)$\n",
        "\n",
        "For the uniform case, the exact posterior is proportional to:\n",
        "\\[\n",
        "q(x_{t-1}\\mid x_t, x_0) \\propto Q^{(t)}(x_t \\mid x_{t-1}) \\cdot Q_{1:(t-1)}(x_{t-1}\\mid x_0)\n",
        "\\]\n",
        "\n",
        "We work in logits, then sample via Gumbel-max. This mirrors Eq. (3) in D3PM.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Theory:** The exact posterior (Eq. 3 in D3PM) decomposes into two factors:\n",
        "$$q(x_{t-1}\\mid x_t,x_0) \\propto Q^{(t)}(x_t\\mid x_{t-1}) \\cdot Q_{1:t-1}(x_{t-1}\\mid x_0).$$\n",
        "We operate in logits, sum the log-factors, and sample via Gumbel-max. When $t=1$, the posterior collapses to $p(x_0)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Exercise 2: Posterior logits and Gumbel sampling\n",
        "Complete `gather_at` and `q_posterior_logits` (and use `gumbel_max_sample`).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "    # Check: posterior probabilities match empirical samples\n",
        "    K = 3\n",
        "    betas = torch.linspace(0.01, 0.05, 4)\n",
        "    q1 = make_uniform_q_onestep(K, betas)\n",
        "    qcum = cumulative_q(q1)\n",
        "    q1T = q1.transpose(1, 2)\n",
        "\n",
        "    x0 = torch.tensor([0, 1])\n",
        "    xt = torch.tensor([1, 2])\n",
        "    t = torch.tensor([3, 3])\n",
        "\n",
        "    logits = q_posterior_logits(x0, xt, t, q1T, qcum)\n",
        "    probs = torch.softmax(logits, dim=-1)\n",
        "    # empirical\n",
        "    N = 2000\n",
        "    counts = torch.zeros_like(probs)\n",
        "    for _ in range(N):\n",
        "        s = gumbel_max_sample(logits)\n",
        "        for k in range(K):\n",
        "            counts[..., k] += (s == k).float()\n",
        "    emp = counts / N\n",
        "    print(\"Analytic probs:\n",
        "\", probs)\n",
        "    print(\"Empirical probs:\n",
        "\", emp)\n",
        "    assert torch.allclose(probs, emp, atol=0.05)\n",
        "    print(\"Exercise 2 check passed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "def gather_at(a: torch.Tensor, t: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
        "    # Index helper: select rows of a by time t and value x.\n",
        "    t_shape = (x.shape[0],) + (1,) * (x.dim() - 1)\n",
        "    t = t.view(t_shape).to(torch.long)\n",
        "    return a[t - 1, x, :]\n",
        "\n",
        "\n",
        "def q_posterior_logits(x0_logits: torch.Tensor, xt: torch.Tensor, t: torch.Tensor,\n",
        "                       q_one_step_T: torch.Tensor, q_cum: torch.Tensor, eps: float = 1e-9) -> torch.Tensor:\n",
        "    # Compute logits for q(x_{t-1} | x_t, x_0) = log Q^{(t)}(x_t|x_{t-1}) + log Q_{1:t-1}(x_{t-1}|x_0)\n",
        "    if x0_logits.dtype in (torch.int32, torch.int64):\n",
        "        x0_logits = torch.log(F.one_hot(x0_logits, q_cum.shape[-1]).float() + eps)\n",
        "    soft = torch.softmax(x0_logits, dim=-1)\n",
        "\n",
        "    fact1 = gather_at(q_one_step_T, t, xt)  # from x_t\n",
        "    qm = q_cum[t - 2].to(dtype=soft.dtype)   # from x_0\n",
        "    fact2 = torch.einsum('b...k,bkd->b...d', soft, qm)\n",
        "\n",
        "    logits = torch.log(fact1 + eps) + torch.log(fact2 + eps)\n",
        "    t_b = t.view((t.shape[0],) + (1,) * xt.dim())\n",
        "    return torch.where(t_b == 1, x0_logits, logits)\n",
        "\n",
        "\n",
        "def gumbel_max_sample(logits: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
        "    # Categorical sampling via Gumbel-max\n",
        "    noise = -torch.log(-torch.log(torch.clamp(torch.rand_like(logits), eps, 1.0 - eps)))\n",
        "    return torch.argmax(logits + noise, dim=-1)\n",
        "\n",
        "# toy check\n",
        "B = 3\n",
        "x0 = torch.tensor([0, 1, 2])\n",
        "xt = torch.tensor([1, 2, 0])\n",
        "t = torch.tensor([3, 3, 3])\n",
        "q_one_step_T = q1.transpose(1, 2)\n",
        "logits = q_posterior_logits(x0, xt, t, q_one_step_T, qcum)\n",
        "samples = gumbel_max_sample(logits)\n",
        "print('posterior logits shape', logits.shape)\n",
        "print('samples', samples)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3 \u2013 Hybrid loss (VB + CE)\n",
        "We combine a variational bound term matching the model posterior to the true posterior and a cross-entropy on predicted $x_0$ logits (stabilizes training).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Theory:** Training uses a hybrid objective:\n",
        "- Variational bound term $\\mathrm{VB} = \\mathbb{E}[\\mathrm{KL}(q(x_{t-1}\\mid x_t,x_0)\\,||\\,q_\theta(x_{t-1}\\mid x_t))]$ over $t$.\n",
        "- Cross-entropy on predicted $x_0$ logits to stabilize learning.\n",
        "Total: $\\mathcal{L} = \\lambda\\,\\mathrm{VB} + \\mathrm{CE}(\\hat{x}_0, x_0)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Exercise 3: Hybrid loss pieces\n",
        "Implement `vb` and ensure `hybrid_loss` returns sensible values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Check: vb ~ 0 for identical logits; >0 when shifted\n",
        "logits = torch.randn(4, 5)\n",
        "assert vb(logits, logits) < 1e-6\n",
        "logits2 = logits + 1.0\n",
        "assert vb(logits, logits2) > 0\n",
        "\n",
        "# Hybrid loss shape sanity\n",
        "B = 2; K = 4\n",
        "model_logits = torch.randn(B, 1, 1, 1, K)\n",
        "x = torch.randint(0, K, (B, 1, 1, 1))\n",
        "xt = torch.randint(0, K, (B, 1, 1, 1))\n",
        "t = torch.tensor([2, 2])\n",
        "q1 = make_uniform_q_onestep(K, torch.linspace(0.01, 0.1, 3))\n",
        "qcum = cumulative_q(q1)\n",
        "q1T = q1.transpose(1, 2)\n",
        "loss, info = hybrid_loss(model_logits, x, xt, t, q1T, qcum)\n",
        "print('Loss', loss.item(), 'info', info)\n",
        "print(\"Exercise 3 check passed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "def vb(dist1_logits: torch.Tensor, dist2_logits: torch.Tensor, eps: float = 1e-9) -> torch.Tensor:\n",
        "    # KL-like term between two categorical distributions given logits.\n",
        "    dist1 = dist1_logits.reshape(-1, dist1_logits.shape[-1])\n",
        "    dist2 = dist2_logits.reshape(-1, dist2_logits.shape[-1])\n",
        "    p1 = torch.softmax(dist1 + eps, dim=-1)\n",
        "    return torch.mean(torch.sum(p1 * (torch.log_softmax(dist1 + eps, dim=-1) - torch.log_softmax(dist2 + eps, dim=-1)), dim=-1))\n",
        "\n",
        "\n",
        "def hybrid_loss(model_logits: torch.Tensor, x: torch.Tensor, xt: torch.Tensor, t: torch.Tensor,\n",
        "                q_one_step_T: torch.Tensor, q_cum: torch.Tensor, hybrid_coeff: float = 0.001):\n",
        "    # Hybrid objective: lambda * VB + CE on x0.\n",
        "    true_post = q_posterior_logits(x, xt, t, q_one_step_T, q_cum)\n",
        "    pred_post = q_posterior_logits(model_logits, xt, t, q_one_step_T, q_cum)\n",
        "    vb_loss = vb(true_post, pred_post)\n",
        "\n",
        "    B = model_logits.shape[0]\n",
        "    ce_loss = F.cross_entropy(model_logits.reshape(B, -1, model_logits.shape[-1]).flatten(0,1), x.flatten(), reduction='mean')\n",
        "    total = hybrid_coeff * vb_loss + ce_loss\n",
        "    return total, {'vb': vb_loss.item(), 'ce': ce_loss.item()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4 \u2013 Small conditional model (UNet-lite)\n",
        "A compact UNet-style network to predict $x_0$ logits given $x_t$, time $t$, and optional class label.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Theory:** A compact UNet-like model predicts $x_0$ logits conditioned on time $t$ and optional class $y$.\n",
        "- Sinusoidal time embedding modulates features at multiple scales.\n",
        "- Label embeddings are added per scale for class-conditional sampling.\n",
        "- Output logits are reshaped to `[B, C, H, W, K]` (per-pixel categorical logits).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "class TinyX0Model(nn.Module):\n",
        "    \"\"\"Small UNet-like predictor for x0 logits.\"\"\"\n",
        "    def __init__(self, n_classes: int, img_channels: int = 1, base_channels: int = 32, cond_classes: int = 10, t_dim: int = 32):\n",
        "        super().__init__()\n",
        "        # Project time and condition to feature dims matching each scale\n",
        "        self.t_proj1 = nn.Linear(t_dim, base_channels)\n",
        "        self.t_proj2 = nn.Linear(t_dim, base_channels * 2)\n",
        "        self.cond_emb = nn.Embedding(cond_classes, base_channels)\n",
        "        self.cond_proj2 = nn.Linear(base_channels, base_channels * 2)\n",
        "\n",
        "        self.down1 = conv_block(img_channels, base_channels)\n",
        "        self.down2 = conv_block(base_channels, base_channels * 2)\n",
        "        self.pool = nn.AvgPool2d(2)\n",
        "\n",
        "        self.up1 = up_block(base_channels * 2, base_channels)\n",
        "        self.up2 = conv_block(base_channels, base_channels)\n",
        "        self.final = nn.Conv2d(base_channels, n_classes * img_channels, 1)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x, t, y=None):\n",
        "        # Scale x to [-1,1] for stability\n",
        "        x = (2 * x.float() / (self.n_classes - 1)) - 1.0\n",
        "        emb_t = sinusoidal_time_embed(t.float(), 32)\n",
        "        t1 = self.t_proj1(emb_t).unsqueeze(-1).unsqueeze(-1)\n",
        "        t2 = self.t_proj2(emb_t).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        cond_raw = 0\n",
        "        cond1 = 0\n",
        "        cond2 = 0\n",
        "        if y is not None:\n",
        "            cond_raw = self.cond_emb(y)\n",
        "            cond1 = cond_raw.unsqueeze(-1).unsqueeze(-1)\n",
        "            cond2 = self.cond_proj2(cond_raw).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        h1 = self.down1(x) + t1 + cond1\n",
        "        h2 = self.down2(self.pool(h1)) + t2 + cond2\n",
        "        h = self.up1(h2)\n",
        "        h = self.up2(h + h1)\n",
        "        out = self.final(h)\n",
        "        out = out.reshape(out.shape[0], -1, self.n_classes, *x.shape[2:]).transpose(2, -1).contiguous()\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5 \u2013 D3PM wrapper (forward, loss, sampling)\n",
        "Slim wrapper around forward noising, loss, and sampling. Based on the minimal implementation in `d3pm_runner.py`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Theory:** The wrapper handles forward noising, posterior utilities, loss, and reverse sampling.\n",
        "- Forward: sample $x_t \\sim q(x_t\\mid x_0)$ using cumulative $Q_{1:t}$ + Gumbel noise.\n",
        "- Reverse step: model logits $\to$ posterior logits $q_\theta(x_{t-1}\\mid x_t)$ $\to$ Gumbel-max sample.\n",
        "- Sampling loop: iterate $t=T\\dots1$, skipping noise on the final step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Exercise 4: Forward noising `_q_sample`\n",
        "Use the cumulative Q and Gumbel to sample $x_t$ from $x_0$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Exercise 5: One reverse step `p_sample`\n",
        "Use model logits \u2192 posterior \u2192 Gumbel-max; mask noise when t==1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Check: with identity logits, p_sample should preserve xt (except final step)\n",
        "class IdentityModel(nn.Module):\n",
        "    def __init__(self, K): super().__init__(); self.K = K\n",
        "    def forward(self, xt, t, y=None):\n",
        "        return torch.log(F.one_hot(xt, self.K).float() + 1e-9)\n",
        "\n",
        "K = 3\n",
        "betas = torch.linspace(0.01, 0.05, 4)\n",
        "d3pm_id = D3PM(IdentityModel(K), n_T=4, num_classes=K, betas=betas)\n",
        "xt = torch.tensor([[0,1],[1,2]])\n",
        "t = torch.tensor([2,2])\n",
        "xt_prev = d3pm_id.p_sample(xt, t)\n",
        "assert torch.equal(xt_prev, xt)\n",
        "print(\"Exercise 5 check passed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n",
        "# Check: _q_sample outputs valid classes\n",
        "K = 3\n",
        "betas = torch.linspace(0.01, 0.05, 4)\n",
        "tmp_model = TinyX0Model(K)\n",
        "d3pm_tmp = D3PM(tmp_model, n_T=4, num_classes=K, betas=betas)\n",
        "x0 = torch.tensor([[0,1],[1,2]])\n",
        "t = torch.tensor([2,3])\n",
        "noise = torch.rand((*x0.shape, K))\n",
        "xt = d3pm_tmp._q_sample(x0, t, noise)\n",
        "assert xt.shape == x0.shape\n",
        "assert (xt >= 0).all() and (xt < K).all()\n",
        "print(\"Exercise 4 check passed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "class D3PM(nn.Module):\n",
        "    \"\"\"Minimal D3PM wrapper: forward noising, loss, reverse sampling.\"\"\"\n",
        "    def __init__(self, x0_model: nn.Module, n_T: int, num_classes: int, betas: torch.Tensor, hybrid_coeff: float = 0.001):\n",
        "        super().__init__()\n",
        "        self.x0_model = x0_model\n",
        "        self.n_T = n_T\n",
        "        self.num_classes = num_classes\n",
        "        self.hybrid_coeff = hybrid_coeff\n",
        "\n",
        "        q_onestep = make_uniform_q_onestep(num_classes, betas)\n",
        "        q_cum = cumulative_q(q_onestep)\n",
        "        self.register_buffer('q_onestep', q_onestep)\n",
        "        self.register_buffer('q_one_step_T', q_onestep.transpose(1, 2))\n",
        "        self.register_buffer('q_cum', q_cum)\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def _q_sample(self, x0: torch.Tensor, t: torch.Tensor, noise: torch.Tensor) -> torch.Tensor:\n",
        "        # Sample x_t ~ q(x_t | x0) using cumulative Q and Gumbel noise.\n",
        "        logits = torch.log(gather_at(self.q_cum, t, x0) + self.eps)\n",
        "        return gumbel_max_sample(logits + torch.log(noise))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: torch.Tensor = None):\n",
        "        # Training step: pick random t, corrupt x0->xt, predict logits, compute loss.\n",
        "        B = x.shape[0]\n",
        "        t = torch.randint(1, self.n_T, (B,), device=x.device)\n",
        "        noise = torch.rand((*x.shape, self.num_classes), device=x.device)\n",
        "        xt = self._q_sample(x, t, noise)\n",
        "\n",
        "        model_logits = self.x0_model(xt, t, y)\n",
        "        loss, info = hybrid_loss(model_logits, x, xt, t, self.q_one_step_T, self.q_cum, self.hybrid_coeff)\n",
        "        return loss, info\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def p_sample(self, xt: torch.Tensor, t: torch.Tensor, y: torch.Tensor = None) -> torch.Tensor:\n",
        "        # One reverse step: model logits -> posterior -> sample (skip noise at t=1).\n",
        "        model_logits = self.x0_model(xt, t, y)\n",
        "        pred_post = q_posterior_logits(model_logits, xt, t, self.q_one_step_T, self.q_cum)\n",
        "        noise = torch.rand((*xt.shape, self.num_classes), device=xt.device)\n",
        "        t_b = t.view((t.shape[0],) + (1,) * xt.dim())\n",
        "        mask = (t_b != 1).float()\n",
        "        gumbel = -torch.log(-torch.log(torch.clamp(noise, self.eps, 1.0 - self.eps)))\n",
        "        sample = torch.argmax(pred_post + gumbel * mask, dim=-1)\n",
        "        return sample\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, shape, y=None, stride: int = 20):\n",
        "        # Full reverse chain for generation; collect frames every `stride`.\n",
        "        B = shape[0]\n",
        "        xt = torch.randint(0, self.num_classes, shape, device=self.q_cum.device)\n",
        "        imgs = []\n",
        "        for step, t_int in enumerate(reversed(range(1, self.n_T))):\n",
        "            t = torch.tensor([t_int] * B, device=xt.device)\n",
        "            xt = self.p_sample(xt, t, y)\n",
        "            if step % stride == 0 or t_int == 1:\n",
        "                imgs.append(xt.detach().cpu())\n",
        "        return imgs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6 \u2013 Data and discretization\n",
        "Use MNIST and discretize pixel values into a small number of bins (N) to keep the state space small and sampling fast.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "N_CLASSES = 4  # discretization bins\n",
        "IMG_CHANNELS = 1\n",
        "BATCH_SIZE = 128\n",
        "N_T = 200  # diffusion steps (small for speed)\n",
        "BETAS = torch.linspace(1e-3, 0.1, N_T)\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_ds = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "print('Train set size', len(train_ds))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 7 \u2013 Training (short run)\n",
        "Brief training loop to keep runtime manageable. Loss values are coarse but enough to sample.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "**Theory/practice:** Training samples a random $t$, corrupts $x_0\to x_t$, predicts logits, and applies the hybrid loss.\n",
        "- We keep epochs/steps small for classroom runtime; expect noisy but usable samples.\n",
        "- Gradient clipping helps with stability on small models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model = TinyX0Model(n_classes=N_CLASSES, img_channels=IMG_CHANNELS).to(DEVICE)\n",
        "d3pm = D3PM(model, n_T=N_T, num_classes=N_CLASSES, betas=BETAS.to(DEVICE)).to(DEVICE)\n",
        "opt = torch.optim.AdamW(d3pm.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 2  # keep small\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    d3pm.train()\n",
        "    running = {'loss': 0, 'vb': 0, 'ce': 0}\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(DEVICE)\n",
        "        y = y.to(DEVICE)\n",
        "        x_disc = (x * (N_CLASSES - 1)).round().long().clamp(0, N_CLASSES - 1)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss, info = d3pm(x_disc, y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(d3pm.parameters(), 1.0)\n",
        "        opt.step()\n",
        "\n",
        "        running['loss'] += loss.item()\n",
        "        running['vb'] += info['vb']\n",
        "        running['ce'] += info['ce']\n",
        "        if (i + 1) % 100 == 0:\n",
        "            n = i + 1\n",
        "            print(f\"Epoch {epoch} Step {n}: loss {running['loss']/n:.3f} | vb {running['vb']/n:.3f} | ce {running['ce']/n:.3f}\")\n",
        "    print('Epoch done')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 8 \u2013 Sampling\n",
        "Reverse the chain to generate samples. We record frames every `stride` steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d3pm.eval()\n",
        "with torch.no_grad():\n",
        "    y = torch.arange(0, 16, device=DEVICE) % 10  # class labels\n",
        "    imgs_seq = d3pm.sample((16, 1, 32, 32), y=y, stride=40)\n",
        "\n",
        "final = imgs_seq[-1].float() / (N_CLASSES - 1)\n",
        "grid = vutils.make_grid(final, nrow=4)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.axis('off')\n",
        "plt.imshow(grid.permute(1,2,0), vmin=0, vmax=1, cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 9 \u2013 Interactive probe (forward corruption)\n",
        "Use a slider over $t$ to visualize how a single image is corrupted by $Q_{1:t}$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import ipywidgets as widgets\n",
        "\n",
        "x0_img, _ = next(iter(train_loader))\n",
        "x0_img = x0_img[:1].to(DEVICE)\n",
        "x0_disc = (x0_img * (N_CLASSES - 1)).round().long().clamp(0, N_CLASSES - 1)\n",
        "\n",
        "@widgets.interact(t=(1, min(50, N_T), 1))\n",
        "def show_corruption(t=1):\n",
        "    with torch.no_grad():\n",
        "        logits = torch.log(gather_at(d3pm.q_cum, torch.tensor([t], device=DEVICE), x0_disc) + d3pm.eps)\n",
        "        xt = torch.argmax(logits, dim=-1)\n",
        "        img = (xt.float() / (N_CLASSES - 1)).cpu()\n",
        "    plt.figure(figsize=(3,3)); plt.axis('off');\n",
        "    plt.imshow(img[0,0], cmap='gray', vmin=0, vmax=1)\n",
        "    plt.title(f't={t}')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}